{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed79dae",
   "metadata": {},
   "source": [
    "# Importing Libraries and Storing Googles Word2vec libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e97edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###############################################################################################################################\n",
    "\n",
    "#Downloading Googles Word2Vec library to be used in all word to vec models using a pretrained model by google\n",
    "#download \"GoogleNews-vectors-negative300.bin\" \n",
    "modl = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#vocab = stores all the words in google Word2vec model\n",
    "vocab = modl.index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3f72c",
   "metadata": {},
   "source": [
    "# Result Visualization\n",
    "#### TF-IDF, Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122ff7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for results \n",
    "def display_img(url):\n",
    "    #Get url of the product and download it\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.imshow(img)\n",
    "\n",
    "def heatmap_image(keys,values,labels,url,text):\n",
    "    #keys gives the list of words for recommended title\n",
    "    #divide the figure into two parts\n",
    "    \n",
    "    gs = gridspec.GridSpec(1,2,width_ratios = [4,1])\n",
    "    fg = plt.figure(figsize=(25,3))\n",
    "    \n",
    "    #1st figure plotting a heatmap that represents the most commonly occuring words\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax = sns.heatmap(np.array([values]),annot=np.array([labels]))\n",
    "    ax.set_xticklabels(keys)\n",
    "    ax.set_title(text)                 \n",
    "    \n",
    "    #2nd figure plotting a heatmap that represents the image of the product\n",
    "    ln = plt.subplot(gs[1])\n",
    "    ln.set_xticks([])\n",
    "    ln.set_yticks([])\n",
    "    \n",
    "    fig = display_img(url)\n",
    "    \n",
    "    #display combine figure\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_image_plot(doc_id,vec1,vec2,url,text,model,tfidf_title_vectorizer,tfidf_title_features,idf_title_vectorizer,idf_title_features):\n",
    "    \n",
    "                     \n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    \n",
    "    #set the value of non intersecting word to zero in vec2                 \n",
    "    for i in vec2.keys():\n",
    "        if i not in intersection:\n",
    "            vec2[i]=0\n",
    "    #if ith word in intersection(list of words of title1 and list of words of title2): values(i)=count of that word in title2 else values(i)=0                 \n",
    "    values = [vec2[x] for x in vec2.keys()]\n",
    "    \n",
    "    #labels for heatmap\n",
    "    keys = list(vec2.keys())\n",
    "                     \n",
    "    if model == 'bag_of_words':\n",
    "        labels = values\n",
    "    \n",
    "    elif model == 'Tfidf':\n",
    "        labels = []\n",
    "        for i in vec2.keys():\n",
    "            if i in tfidf_title_vectorizer.vocabulary_:\n",
    "                #idf_title_vectorizer.vocabulary contains all the words in the corpus         \n",
    "                labels.append(tfidf_title_features[doc_id,tfidf_title_vectorizer.vocabulary_[i]])\n",
    "        \n",
    "            else:\n",
    "                labels.append(0)\n",
    "    elif model == 'idf':\n",
    "        labels = []\n",
    "        for i in vec2.keys():\n",
    "            if i in idf_title_vectorizer.vocabulary_:\n",
    "                #idf_title_vectorizer.vocabulary contains all the words in the corpus         \n",
    "                labels.append(idf_title_features[doc_id,idf_title_vectorizer.vocabulary_[i]])\n",
    "        \n",
    "            else:\n",
    "                labels.append(0)\n",
    "                     \n",
    "    heatmap_image(keys,values,labels,url,text)\n",
    "                     \n",
    "                     \n",
    "def text_vector(sentence):\n",
    "    words = sentence.split()    \n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def visualization(doc_id,sentence1,sentence2,url,model,tfidf_title_vectorizer,tfidf_title_features,idf_title_vectorizer,idf_title_features):\n",
    "    vec1 = text_vector(sentence1)\n",
    "    vec2 = text_vector(sentence2)\n",
    "                     \n",
    "    heatmap_image_plot(doc_id,vec1,vec2,url,sentence2,model,tfidf_title_vectorizer,tfidf_title_features,idf_title_vectorizer,idf_title_features)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca878e9c",
   "metadata": {},
   "source": [
    "#### Avg Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce57ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function to better visualize and understand results\n",
    "\n",
    "def get_word_vec(sentence,doc_id,model_name,idf_title_vectorizer,idf_title_features):\n",
    "    #doc_id : index id in vectorized array\n",
    "    #sentence : title of product\n",
    "    #model_name : 'avg', we will append the model[i], w2v representation of word i\n",
    "    \n",
    "    vec = []\n",
    "    for i in sentence.split():\n",
    "        if i in vocab:\n",
    "            if model_name == 'avg':\n",
    "                vec.append(modl[i])\n",
    "            elif model_name == 'weighted' and i in idf_title_vectorizer.vocabulary_:\n",
    "                vec.append(idf_title_features[doc_id,idf_title_vectorizer.vocabulary_[i]] * modl[i] )\n",
    "        else:\n",
    "            vec.append(np.zeros(shape=(300,)))\n",
    "    return np.array(vec)\n",
    "def get_distance(vec1,vec2):\n",
    "    # vec1 = np.array(#number_of_words_title1 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
    "    # vec2 = np.array(#number_of_words_title2 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
    "    final_dist = []\n",
    "    for i in vec1:\n",
    "        dist = []\n",
    "        for j in vec2:\n",
    "            dist.append(np.linalg.norm(i-j))\n",
    "        final_dist.append(np.array(dist))\n",
    "            \n",
    "    return np.array(final_dist)\n",
    "\n",
    "def results_Word2Vec(sentence1,sentence2,url,doc_id1,doc_id2,model_name,idf_title_vectorizer,idf_title_features):\n",
    "    # sentence1 : title1, input product\n",
    "    # sentence2 : title2, recommended product\n",
    "    # model:  'avg'\n",
    "\n",
    "    sentence_vec1 = get_word_vec(sentence1,doc_id1,model_name,idf_title_vectorizer,idf_title_features)\n",
    "    sentence_vec2 = get_word_vec(sentence2,doc_id2,model_name,idf_title_vectorizer,idf_title_features)\n",
    "    \n",
    "    #sent1_sent2_dist = eucledian distance between i and j\n",
    "    #sent1_sent2_dist = np array with dimensions(#number of words in title1 * #number of words in title2)\n",
    "    sent1_sent2_dist = get_distance(sentence_vec1,sentence_vec2)\n",
    "    \n",
    "    # divide whole figure into 2 parts 1st part displays heatmap 2nd part displays image of products\n",
    "    \n",
    "    gs = gridspec.GridSpec(1,2,width_ratios=[4,1])\n",
    "    fg = plt.figure(figsize=(15,15))\n",
    "    \n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax = sns.heatmap(np.round(sent1_sent2_dist,3), annot = True)\n",
    "    ax.set_xticklabels(sentence2.split())\n",
    "    # set the y axis labels as input product title\n",
    "    ax.set_yticklabels(sentence1.split())\n",
    "    # set title as recommended product title\n",
    "    ax.set_title(sentence2)\n",
    "    \n",
    "    #setting the fontsize and rotation of x tick tables\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12,rotation=90)\n",
    "    ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12,rotation=45)\n",
    "    \n",
    "    fg = plt.subplot(gs[1])\n",
    "    fg.set_xticks([])\n",
    "    fg.set_yticks([])\n",
    "    fig = display_img(url)\n",
    "    \n",
    "    #display combine figure\n",
    "    plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
